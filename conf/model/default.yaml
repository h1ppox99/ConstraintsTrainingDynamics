# @package _global_.model
backbone_type: mlp     # "mlp" or "transformer"

# --- MLP backbone ---
hidden_dim: 200
n_hidden: 3
dropout: 0.1
use_batchnorm: true

# --- Transformer backbone ---
d_model: 64
n_heads: 4
n_layers: 3
dim_feedforward: 128
n_tokens: 8

# --- Theseus solver ---
theseus_maxiter: 30

# --- CVXPY solver ---
cvxpy_solver_eps: 1e-5
cvxpy_solver_max_iters: 10000
